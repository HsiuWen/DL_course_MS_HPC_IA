{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Convolutional Neural Network \n",
    "This notebook has been prepared by Hsiu-Wen (Kelly) Chang from MINES ParisTech for the class of HPC-AI 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this lab, we will continue the same task in Lab 1 but with CNN artecture to improve the performance. This time we use pacakges from pyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous in lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "39.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "66.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size_train = 64 # batch size\n",
    "batch_size_test = 1000\n",
    "lr = 0.01 # learning rate\n",
    "epochs = 10 # training epochs\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship  plane cat   dog  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call ``model.train()`` before training, and ``model.eval()``\n",
    "before inference, because these are used by layers such as ``nn.BatchNorm2d``\n",
    "and ``nn.Dropout`` to ensure appropriate behaviour for these different phases.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_608811/1828936369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_course_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_608811/2177287772.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten all dimensions except batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_course_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_course_env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_course_env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final three lines code\n",
    "\n",
    "Create fit() and get_data()\n",
    "\n",
    "(1) Define a function ``loss_batch`` which computes the loss for one batch.\n",
    "\n",
    "We pass an optimizer in for the training set, and use it to perform\n",
    "backprop.  For the validation set, we don't pass an optimizer, so the\n",
    "method doesn't perform backprop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) ``fit`` runs the necessary operations to train our model and compute the training and validation losses for each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# meaning of * is to unpacks a list or tuple into position arguments\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train() #set the mode to training mode. if we use model.train(false), it will become evaluation mode\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ``get_data`` returns dataloaders for the training and validation sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the\n",
    "model can be run in 3 lines of code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6317909804344177\n",
      "1 0.48972965540885927\n",
      "2 0.43378640098571775\n",
      "3 0.40269780976772307\n",
      "4 0.38283069169521333\n",
      "5 0.36854054698944094\n",
      "6 0.3575570048093796\n",
      "7 0.34911181468963626\n",
      "8 0.342390913271904\n",
      "9 0.3364930906534195\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: plot loss values and validations values\n",
    "In order to understand the progress of your training, error curves with test and validation are very common to be shown.\n",
    "Change your code in order to see the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use these basic 3 lines of code to train a wide variety of models.\n",
    "Let's see if we can use them to train a convolutional neural network (CNN)!\n",
    "\n",
    "Switch to CNN\n",
    "-------------\n",
    "\n",
    "We are now going to build our neural network with three convolutional layers.\n",
    "Because none of the functions in the previous section assume anything about\n",
    "the model form, we'll be able to use them to train a CNN without any modification.\n",
    "\n",
    "We will use Pytorch's predefined\n",
    "`Conv2d <https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d>`_ class\n",
    "as our convolutional layer. We define a CNN with 3 convolutional layers.\n",
    "Each convolution is followed by a ReLU.  At the end, we perform an\n",
    "average pooling.  (Note that ``view`` is PyTorch's version of numpy's\n",
    "``reshape``)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Momentum <https://cs231n.github.io/neural-networks-3/#sgd>`_ is a variation on\n",
    "stochastic gradient descent that takes previous updates into account as well\n",
    "and generally leads to faster training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.382933112180233\n",
      "1 0.2702909678697586\n",
      "2 0.20762188514471053\n",
      "3 0.18016452248990536\n",
      "4 0.1900676942527294\n",
      "5 0.1664056705713272\n",
      "6 0.14920399511754512\n",
      "7 0.17533807607293128\n",
      "8 0.13726386784613132\n",
      "9 0.13912812107503414\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential\n",
    "------------------------\n",
    "\n",
    "``torch.nn`` has another handy class we can use to simply our code:\n",
    "`Sequential <https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential>`_ .\n",
    "A ``Sequential`` object runs each of the modules contained within it, in a\n",
    "sequential manner. This is a simpler way of writing our neural network.\n",
    "\n",
    "To take advantage of this, we need to be able to easily define a\n",
    "**custom layer** from a given function.  For instance, PyTorch doesn't\n",
    "have a `view` layer, and we need to create one for our network. ``Lambda``\n",
    "will create a layer that we can then use when defining a network with\n",
    "``Sequential``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model created with ``Sequential`` is simply:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.36149111242294313\n",
      "1 0.2670303117990494\n",
      "2 0.22516312140226363\n",
      "3 0.2877102443575859\n",
      "4 0.17123320768177508\n",
      "5 0.16590370565652848\n",
      "6 0.1554075716018677\n",
      "7 0.14590528378486634\n",
      "8 0.1460394793987274\n",
      "9 0.13605394797325135\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping DataLoader\n",
    "-----------------------------\n",
    "\n",
    "Our CNN is fairly concise, but it only works with MNIST, because:\n",
    " - It assumes the input is a 28\\*28 long vector\n",
    " - It assumes that the final CNN grid size is 4\\*4 (since that's the average\n",
    "pooling kernel size we used)\n",
    "\n",
    "Let's get rid of these two assumptions, so our model works with any 2d\n",
    "single channel image. First, we can remove the initial Lambda layer but\n",
    "moving the data preprocessing into a generator:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kelly: I am not so sure why this one can deal with any size of 2d image...\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can replace ``nn.AvgPool2d`` with ``nn.AdaptiveAvgPool2d``, which\n",
    "allows us to define the size of the *output* tensor we want, rather than\n",
    "the *input* tensor we have. As a result, our model will work with any\n",
    "size input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.33848215029239653\n",
      "1 0.3312550708770752\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your GPU\n",
    "---------------\n",
    "\n",
    "If you're lucky enough to have access to a CUDA-capable GPU (you can\n",
    "rent one for about $0.50/hour from most cloud providers) you can\n",
    "use it to speed up your code. First check that your GPU is working in\n",
    "Pytorch:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create a device object for it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update ``preprocess`` to move batches to the GPU:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can move our model to the GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find it runs faster now:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing thoughts\n",
    "-----------------\n",
    "\n",
    "We now have a general data pipeline and training loop which you can use for\n",
    "training many types of models using Pytorch. To see how simple training a model\n",
    "can now be, take a look at the `mnist_sample` sample notebook.\n",
    "\n",
    "Of course, there are many things you'll want to add, such as data augmentation,\n",
    "hyperparameter tuning, monitoring training, transfer learning, and so forth.\n",
    "These features are available in the fastai library, which has been developed\n",
    "using the same design approach shown in this tutorial, providing a natural\n",
    "next step for practitioners looking to take their models further.\n",
    "\n",
    "We promised at the start of this tutorial we'd explain through example each of\n",
    "``torch.nn``, ``torch.optim``, ``Dataset``, and ``DataLoader``. So let's summarize\n",
    "what we've seen:\n",
    "\n",
    " - **torch.nn**\n",
    "\n",
    "   + ``Module``: creates a callable which behaves like a function, but can also\n",
    "     contain state(such as neural net layer weights). It knows what ``Parameter`` (s) it\n",
    "     contains and can zero all their gradients, loop through them for weight updates, etc.\n",
    "   + ``Parameter``: a wrapper for a tensor that tells a ``Module`` that it has weights\n",
    "     that need updating during backprop. Only tensors with the `requires_grad` attribute set are updated\n",
    "   + ``functional``: a module(usually imported into the ``F`` namespace by convention)\n",
    "     which contains activation functions, loss functions, etc, as well as non-stateful\n",
    "     versions of layers such as convolutional and linear layers.\n",
    " - ``torch.optim``: Contains optimizers such as ``SGD``, which update the weights\n",
    "   of ``Parameter`` during the backward step\n",
    " - ``Dataset``: An abstract interface of objects with a ``__len__`` and a ``__getitem__``,\n",
    "   including classes provided with Pytorch such as ``TensorDataset``\n",
    " - ``DataLoader``: Takes any ``Dataset`` and creates an iterator which returns batches of data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_course_env",
   "language": "python",
   "name": "dl_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
