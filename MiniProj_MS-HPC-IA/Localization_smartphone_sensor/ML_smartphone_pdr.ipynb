{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a32363",
   "metadata": {},
   "source": [
    "# Project: user's heading and speed estimation with smartphon IMU sensors\n",
    "This is created by Hsiu-Wen Chang Joly, Date: 28, Nov., 2022\n",
    "\n",
    "* Background: Pedestrian Dead Reckoning (PDR) uses inertial measurement units (IMUs) and combines displacement (velocity) and orientation estimates to determine a position. The estimation of the displacement(or velocity) is still challenging, as the integration of noisy acceleration and angular speed signals over a long period oftime causes large drifts. Classic approaches to estimate the displacement optimize for specific applications,sensor positions, and types of movement and require extensive parameter tuning.\n",
    "\n",
    "Classical PDR: the 2D position of the new step $$p(k) = [x,y] = [d_k*cos(\\theta), d(k)*sin(\\theta)]+p(k-1)$$ where d_k is the k-th step length, theta_k is the heading of human body, p(k-1) is the position of last step.\n",
    "\n",
    "Simiplifed way: if we knows the average of heading $\\hat{\\theta}$ of the user from $t_{k}$ to $t_{k+n}$ and its corresponding average speed $\\hat{v}$, then the position of the user at $t_k$ is simply the integration\n",
    "$$p(k) = [\\hat{v}*dt*cos(\\hat{\\theta}), \\hat{v}*dtsin(\\hat{\\theta})]+p(k-1)$$\n",
    "\n",
    "* task: use one seconds of IMU data (gyro reading, accelerometer readings) from smartphone to predict the heading and speed ($\\hat{\\theta}$,$\\hat{v}$). Generate position at 1 Hz rate (However, it doesn't mean you have to generate training sample exactly the same way)\n",
    "\n",
    "* candidate architectures: CNN, LSTN\n",
    "\n",
    "* Data description: \n",
    "Each folder represents 1 trajectory with random user's behavior (phone in pocket, hold it and swing arm, texting).\n",
    "Inside each folder, *.hdf5 contains processed IMU data (time sychronization, bias removal, levelling)\n",
    "Ground truth (Pay attention! they are not directly speed and angle. They are horizonal speed [vx,vy]) are generated by Google tangle that fixed stably in front of the human chest. You shall preprocess your target array\n",
    "\n",
    "\n",
    "Advance option: create your own data by using your phone. Do finetuning with the following step\n",
    "1) read read http://sensorlog.berndthomas.net/ to have the format of file. \n",
    "2) leveled accelerationa and gyroscope using roll and pitch.\n",
    "3) create ground-truth (you can measure the walking distance and walked in a building with known indoor map. Manually key in 2D velocity)\n",
    "4) create your dataloader\n",
    "5) Start training!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e07d2",
   "metadata": {},
   "source": [
    "***What to submit***\n",
    "\n",
    "The expected content of the this project's report should contains:\n",
    "1. Basic description of the background\n",
    "2. performance of ML with different data augmentation, architecture, loss function, time comsumption\n",
    "3. Albation study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be32ee",
   "metadata": {},
   "source": [
    "## Step 1: Data loading and formatting training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c231633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import os\n",
    "from os import path as osp\n",
    "from tensorboardX import SummaryWriter\n",
    "import json\n",
    "from matplotlib.ticker import MultipleLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498a001",
   "metadata": {},
   "source": [
    "### Introduction to h5py file\n",
    "HDF5 (Hierarchical Data Format 5) is an open-source file which stores data in a hierarchical structure. So it enables us to quickely access a particular part of the file rather than the whole file. This is very useful when we do training.\n",
    "### Pricinple knoweldge of data processing\n",
    "1. Unix time is a way of representing a timestamp by representing the time as the number of seconds since January 1st, 1970 at 00:00:00 UTC. When you access time log from your phone, they could be given in this format. To make the project simple, you will see the time array has been converted to start at 0, second unit.\n",
    "2. Unit for gyro reading is in rad/s. \n",
    "3. Unit for acceleration is in m/s/s\n",
    "3. For process IMU data like Image application, we feed 1 seconds (you can change it for advance experience) of gyro and accelerometer's reading to our model. The provided data set is sampled at 200 Hz. In this case, the input array will be 200x6 size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e622998",
   "metadata": {},
   "source": [
    "### Understand the data format from Ronin data benchmark\n",
    "\n",
    "1. Download the smaller size of preprocessed IMU data at [link](https://cloud.minesparis.psl.eu/index.php/s/CzZoYiMojbZ3nUV)\n",
    "and change the data_path to the this folder\n",
    "2. You can find three txt files that help you seperates the data into training, validation and test\n",
    "\n",
    "3. The IMU data (3 accelerations + 3 angular rate) is sampled at 200 Hz. Since every 200 samples has one the groundtruth label, you will find the length of target array has 200 sample less than IMU data. This is not an error, this is a coding way to retreive and portion of IMU easily in class \"MyDataset\", function \"getitem\"\n",
    "\n",
    "4. To predict directly heading (-pi to pi) will have jumping value (such as pi jumps back to -pi), it is recommended to design output directly in quaternion or angle components (using sin and cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444cbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quaternion\n",
    "import math\n",
    "\n",
    "def euler_from_quaternion(w,x,y,z):\n",
    "    \"\"\"Covert a quaternon into euler angels, order in ZYX rotation\"\"\"\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    roll_x = np.arctan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    pitch_y = np.arcsin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    yaw_z = np.arctan2(t3, t4)\n",
    "\n",
    "    return roll_x, pitch_y, yaw_z # in radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we try to see some of the datasets\n",
    "data_path = 'ronin_data_simple'\n",
    "data_list = ['a000_1','a006_2','a039_2']\n",
    "\n",
    "# Read meta data\n",
    "with open(os.path.join(data_path, 'config.json')) as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "#print(f'feature_dim:{info['feature_dim']})\n",
    "# print(info)\n",
    "# os.chdir(data_path)\n",
    "# all_list = glob.glob(\"*.hdf5\")\n",
    "# print(all_list)\n",
    "\n",
    "# Read provided data\n",
    "features_all, targets_all, aux_all = [], [], []\n",
    "for i in range(len(data_list)):\n",
    "    with h5py.File(os.path.join(data_path, data_list[i] + '.hdf5')) as f:\n",
    "        feat = np.copy(f['feature']) # 3 accelerations and 3 angular rates, projected and given in local level frame at t0\n",
    "        #targ = np.copy(f['target']) # original target is local 2D speed, [vx,vy]\n",
    "        aux = np.copy(f['aux']) #timetage(ts), groundtruth orientation (q), ground-truth position(x,y,h)\n",
    "        dt = (aux[1:,0] - aux[:-1,0])[:, None]\n",
    "        glob_v = (aux[1:,6:8] - aux[:-1,6:8]) / dt\n",
    "\n",
    "        speed = np.linalg.norm(glob_v, axis=1).reshape(-1,1)\n",
    "        speed = np.concatenate(([speed,[speed[-1]]]))\n",
    "  \n",
    "        #body_heading = orientation_to_angles(aux[200:,1:5])[:,0]\n",
    "        targ = np.concatenate(([speed, aux[:,1:5]]), axis=-1) # use this for predicting quaternion\n",
    "        #print(targ.shape)\n",
    "        #print(feat.shape)\n",
    "    features_all.append(feat)\n",
    "    targets_all.append(targ)\n",
    "    aux_all.append(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca28b40",
   "metadata": {},
   "source": [
    "## Step 2: Display some of the timeseries (Sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data\n",
    "## Plot the position (ground truth) from Tangle phone\n",
    "traj_ID = 1 # feel free to change it so you can see other trajectories.\n",
    "tango_pos=aux_all[traj_ID][:,5:7]\n",
    "ts = aux_all[traj_ID][:,0]\n",
    "\n",
    "speed = targets_all[traj_ID][:,0]\n",
    "#ody_heading = orientation_to_angles(targets_all[traj_ID][:,1:5])\n",
    "body_heading = np.array([euler_from_quaternion(*q) for q in targets_all[traj_ID][:,1:5]])\n",
    "print(body_heading.shape)\n",
    "acce = features_all[traj_ID][:,3:]\n",
    "gyro = features_all[traj_ID][:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1= 3750\n",
    "t2 = 3800\n",
    "plt.figure()\n",
    "plt.title(f'Position from Tangle for data {data_list[0]}')\n",
    "#plt.plot(aux_all[traj_ID][:,5],aux_all[traj_ID][:,6]),plt.grid()\n",
    "plt.plot(tango_pos[:,0],tango_pos[:,1])\n",
    "plt.plot(aux_all[traj_ID][0,5],aux_all[traj_ID][0,6],'r*',label=['start']),plt.grid()\n",
    "plt.plot(tango_pos[(ts>t1) & (ts < t2),0], tango_pos[(ts>t1) & (ts < t2),1],'r-',label='test_seg')\n",
    "plt.axis('equal'), plt.legend(), plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(targets_all[traj_ID][:,1:])\n",
    "plt.title('quaternion from ground truth')\n",
    "## Plot speed estimated by Tangle phone\n",
    "fig, ax=plt.subplots(2,1,sharex='col')\n",
    "ax[0].set_title('Groundtruth speed from Tangle')\n",
    "ax[0].plot(ts, speed,label=['speed'])\n",
    "ax[0].set_ylabel('m/s')\n",
    "ax[0].set_xlabel('s')\n",
    "ax[0].legend()\n",
    "ax[1].set_title('Groundtruth heading from Tangle')\n",
    "ax[1].plot(ts, body_heading*180/np.pi,label=['roll','pitch','heading'])\n",
    "#ax[1].plot(ts, targets_all[traj_ID][:,1]*180/np.pi,label=['heading_direct'])\n",
    "ax[1].set_ylabel('deg')\n",
    "ax[1].set_xlabel('s')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9def75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the acceleration from IMU\n",
    "plt.figure()\n",
    "plt.title('Acc')\n",
    "plt.plot(ts,acce, label=('x','y','z')),plt.grid()\n",
    "plt.legend()\n",
    "plt.ylabel('m/s/s')\n",
    "plt.xlabel('s')\n",
    "\n",
    "## Plot the gyro from IMU\n",
    "plt.figure()\n",
    "plt.title('Gyro')\n",
    "plt.plot(ts,gyro*180/np.pi, label=('x','y','z')),plt.grid()\n",
    "plt.ylabel('deg/s')\n",
    "plt.legend()\n",
    "plt.xlabel('s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25f27a",
   "metadata": {},
   "source": [
    "## Step 3: Prepare your dataset and dataloader\n",
    "\n",
    "Here we include the following techniques (data augmentation)\n",
    "1. Shuffle windows order within one trajectory. The number of windows is controlled by argument: step_size\n",
    "2. Randomly pick a trajectory and then randly pick an index to extract one second of data (argument: window_size) within this trajectory\n",
    "3. This window will has random shift index (little possible range, see argument: random_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e678a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class mydataset(Dataset):\n",
    "    feature_dim = 6 # 3 acc + 3 gyro\n",
    "    target_dim = 5 # 1 speed, 4 quaternion\n",
    "    aux_dim = 8 # 8 extra information: ts, 4 truth quaternion, 3 true positions\n",
    "\n",
    "    def __init__(self,root_dir, data_list, step_size=10, window_size=200,random_shift=0, shuffle_fea=True):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.target_dim = target_dim\n",
    "        self.aux_dim = aux_dim\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.random_shift = random_shift\n",
    "        #self.transform = transform # data augmentation by rotate IMU z-axis randomly\n",
    "        self.interval = window_size\n",
    "        self.shuffle_fea = shuffle_fea\n",
    "        self.data_path = [osp.join(root_dir, data) for data in data_list]\n",
    "        self.index_map = [] #used to sample randomly in a trajectory\n",
    "        self.ts, self.orientations, self.gt_pos = [], [], []\n",
    "\n",
    "        if data_path is not None:\n",
    "            self.load(data_path)\n",
    "\n",
    "    def load(self, data_path):\n",
    "        for i in range(len(data_list)):\n",
    "            with h5py.File(os.path.join(data_path, data_list[i] + '.hdf5')) as f:\n",
    "                feat = np.copy(f['feature'])\n",
    "                targ = np.copy(f['target'])\n",
    "                aux = np.copy(f['aux']) #timetage(ts), groundtruth orientation , ground-truth position(x,y,h)\n",
    "                dt = (aux[1:,0] - aux[:-1,0])[:, None]\n",
    "                glob_v = (aux[1:,6:8] - aux[:-1,6:8]) / dt\n",
    "\n",
    "                speed = np.linalg.norm(glob_v, axis=1).reshape(-1,1)\n",
    "                speed = np.concatenate(([speed,[speed[-1]]]))\n",
    "  \n",
    "                targ = np.concatenate(([speed, aux[:,1:5]]), axis=-1) # use this for predicting quaternion\n",
    "            self.features.append(feat)\n",
    "            self.targets.append(targ)\n",
    "            \n",
    "        for i in range(len(data_list)):\n",
    "            self.ts.append(aux[i][:, 0])\n",
    "            self.orientations.append(aux[i][:, 1:5])\n",
    "            self.gt_pos.append(aux[i][:, -3:])\n",
    "            self.index_map += [[i, j] for j in range(0, self.targets[i].shape[0], step_size)]\n",
    "\n",
    "        if self.shuffle_fea:\n",
    "            random.shuffle(self.index_map)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        seq_id, frame_id = self.index_map[item][0], self.index_map[item][1]\n",
    "        if self.random_shift > 0:\n",
    "            frame_id += random.randrange(-self.random_shift, self.random_shift)\n",
    "            frame_id = max(self.window_size, min(frame_id, self.targets[seq_id].shape[0] - 1))\n",
    "\n",
    "        feat = self.features[seq_id][frame_id:frame_id + self.window_size]\n",
    "        targ = self.targets[seq_id][frame_id]\n",
    "\n",
    "        #if self.transform is not None:\n",
    "        #    feat, targ = self.transform(feat, targ)\n",
    "\n",
    "        return feat.astype(np.float32).T, targ.astype(np.float32), seq_id, frame_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call MyDataset to see one example of (input, target)\n",
    "\n",
    "dataloader = mydataset(data_path, data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5751fe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 4: Create your NN to train!\n",
    "\n",
    "Recommended NN candidates: RestNet18, LSTM\n",
    "Questions that you will need to think:\n",
    "(1) heading and speed have two different units. The design of the loss function is therefore, important to balance the behavior of heading performance and speed performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0fa70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a3b01c6",
   "metadata": {},
   "source": [
    "### Advanced option: generated your own dataset by sensorlog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68781ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv2cached(filename,out_path):\n",
    "   \n",
    "    # Reading csv\n",
    "    df = pd.read_csv(filename, sep=\",\",header=0)\n",
    "    if 'locationTimestamp_since1970(s)' not in df.keys():\n",
    "        print(f'wrong csv formate: {filename}')\n",
    "        return\n",
    "\n",
    "    unix_timestamps=df['locationTimestamp_since1970(s)'].to_numpy().astype('float')\n",
    "    timestamps=df['motionTimestamp_sinceReboot(s)'].to_numpy().astype('float')\n",
    "    timestamps=timestamps-timestamps[0]\n",
    "    print(f'Average sampling rate:{1/np.mean(np.diff(timestamps))}')\n",
    "\n",
    "    speed_data=df['locationSpeed(m/s)'].to_numpy().astype('float')*3.6 #unit in km/h\n",
    "    acc_data=df[['motionUserAccelerationX(G)','motionUserAccelerationY(G)','motionUserAccelerationZ(G)']].to_numpy().astype('float')*9.8+df[['motionGravityX(G)','motionGravityY(G)','motionGravityZ(G)']].to_numpy().astype('float')*9.8\n",
    "    if 'accelerometerAccelerationX(G)' in df.keys():\n",
    "        acc_data=df[['accelerometerAccelerationX(G)','accelerometerAccelerationY(G)','accelerometerAccelerationZ(G)']].to_numpy().astype('float')*9.8\n",
    "    acc_data=-acc_data\n",
    "\n",
    "    gyr_data=df[['motionRotationRateX(rad/s)','motionRotationRateY(rad/s)','motionRotationRateZ(rad/s)']].to_numpy().astype('float')\n",
    "\n",
    "    mag_data=df[['motionMagneticFieldX(µT)','motionMagneticFieldY(µT)','motionMagneticFieldZ(µT)']].to_numpy().astype('float')\n",
    "    ea_data=df[['motionRoll(rad)','motionPitch(rad)','motionYaw(rad)']].to_numpy().astype('float')\n",
    "    q_data=quaternion.as_quat_array(df[['motionQuaternionW(R)','motionQuaternionX(R)','motionQuaternionY(R)','motionQuaternionZ(R)']].to_numpy().astype('float'))\n",
    "    pos_data=df[['locationLatitude(WGS84)','locationLongitude(WGS84)','locationAltitude(m)']].to_numpy().astype('float')\n",
    "    grav_data = df[['motionGravityX(G)','motionGravityY(G)','motionGravityZ(G)']].to_numpy().astype('float')\n",
    "    index=np.shape(df.to_numpy())[0]\n",
    "\n",
    "    # Resampling\n",
    "    timestamps200=np.arange(timestamps[0],timestamps[-1],1/200)\n",
    "    acc_data200=np.array([np.interp(timestamps200, timestamps, acc_data[:,i]) for i in range(acc_data.shape[1])]).T\n",
    "    gyr_data200=np.array([np.interp(timestamps200, timestamps, gyr_data[:,i]) for i in range(gyr_data.shape[1])]).T\n",
    "    mag_data200=np.array([np.interp(timestamps200, timestamps, mag_data[:,i]) for i in range(mag_data.shape[1])]).T\n",
    "    pos_data200=np.array([np.interp(timestamps200, timestamps, pos_data[:,i]) for i in range(pos_data.shape[1])]).T\n",
    "    grav_data200=np.array([np.interp(timestamps200, timestamps, grav_data[:,i]) for i in range(grav_data.shape[1])]).T\n",
    "    unix_timestamps200 = np.interp(timestamps200, timestamps, unix_timestamps) \n",
    "    manu_speed200 = np.interp(timestamps200, timestamps, manu_speed[:,0])\n",
    "    q_data200=[]   \n",
    "    ea_data200 =[] \n",
    "    count = 0\n",
    "    ts,te = timestamps[0],timestamps[1]\n",
    "    for i, t_tau in enumerate(timestamps200):\n",
    "        if ts > t_tau:\n",
    "            count += 1\n",
    "            ts = timestamps[count]\n",
    "            te = timestamps[min(count+1, len(timestamps))]\n",
    "\n",
    "        if ts == t_tau or ts == te:\n",
    "            q_data200.append(quaternion.as_float_array(q_data[count]))\n",
    "            ea_data200.append(quaternion.as_euler_angles(q_data[count]))\n",
    "        else:\n",
    "            new_q = quaternion.slerp(q_data[count], q_data[count+1], ts,te,t_tau )\n",
    "            q_data200.append(quaternion.as_float_array(new_q) )\n",
    "            ea_data200.append(quaternion.as_euler_angles(new_q)) \n",
    "    ea_data200=np.array(ea_data200)\n",
    "    \n",
    "    #TODO finalize the format of folders so this function can generate meta by itself. Currently we need to write meta data by ourself\n",
    "    f_name = filename.split('/')[-1] \n",
    "    meta_info = {'type': 'unannotated',\n",
    "                'length': f'{timestamps[-1]-timestamps[0]}',\n",
    "                'date': f'{f_name[8:10]}/{f_name[5:7]}/{f_name[2:4]}',\n",
    "                'device': filename.split('/')[0],\n",
    "                'person': person_name,\n",
    "                'activity': filename.split('/')[1], #TODO: ask to add this naming rule to SOP doc\n",
    "                'manual_speed':speed_list,\n",
    "                'imu_reference_time': unix_timestamps[0].tolist(),\n",
    "    }\n",
    "    json.dump(meta_info, open(osp.join(out_path, 'info.json'), 'w'))\n",
    "    \n",
    "    # resmapling to match 200 HZ for RoNIN networks\n",
    "    timestamps2=np.arange(timestamps[0],timestamps[-1],1/frequence_ronin)\n",
    "\n",
    "    with h5py.File(os.path.join(out_path, 'data.hdf5'), 'x') as f:\n",
    "        #\"raw\" group contains data as reported by APIs in format \n",
    "        # - system_timestamp (nanosecond), API output\n",
    "        f.create_group('raw/imu')\n",
    "        f.create_dataset('raw/system_timestamp200',data=unix_timestamps)\n",
    "        f.create_dataset('raw/imu/gyro',data=gyr_data)\n",
    "        f.create_dataset('raw/imu/gyro_uncalib',data=gyr_data_uncalib) #TODO\n",
    "        f.create_dataset('raw/imu/acce',data=acc_data) #TODO\n",
    "        f.create_dataset('raw/imu/magnet',data=mag_data) #TODO\n",
    "        f.create_dataset('raw/imu/game_rv',data=ea_data) #TODO: make sure it match the defintion since we switch the roll, pitch, yaw order\n",
    "        #f.create_dataset('raw/imu/game_rv',data=ea_data) #TODO\n",
    "\n",
    "        #\"synced\" group contains time synchronized data from IMU device sampled at 200 Hz\n",
    "        # - time : System time of IMU device in seconds  \n",
    "        f.create_group('synced')\n",
    "        f.create_dataset('synced/time', data=timestamps200)\n",
    "        f.create_dataset('synced/gyro', data=gyr_data200)\n",
    "        f.create_dataset('synced/acce', data=acc_data200)\n",
    "        f.create_dataset('synced/magnet', data=mag_data200)\n",
    "        f.create_dataset('synced/game_rv', data=ea_data200)\n",
    "        f.create_dataset('synced/rv', data=ea_data200) #TODO: need to figure the defintion of game rv and rv, currently we use defintion from numpy-quaternion\n",
    "        f.create_dataset('synced/grav',data=grav_data200)\n",
    "        f.create_dataset('synced/manu_speed',data=manu_speed200)\n",
    "        #f.create_dataset('synced/linacce',data=df[].to_numpy().astype('float')) #TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPC_IA_env",
   "language": "python",
   "name": "hpc_ia_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
