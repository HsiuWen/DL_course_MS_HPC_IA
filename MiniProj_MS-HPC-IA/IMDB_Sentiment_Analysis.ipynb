{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b44ce39-46f0-446f-814c-c4e67251d04b",
   "metadata": {},
   "source": [
    "# Contextual Word Sentiment Classification\n",
    "\n",
    "This notebook implements a contextual word sentiment classification model using the IMDb dataset. \n",
    "The goal is to classify individual words as positive, negative, or neutral based on sentence-level sentiment labels, \n",
    "while incorporating the context of neighboring words.\n",
    "\n",
    "\n",
    "**Important**: At the end you should write a report of adequate size, which will probably mean at least half a page. In the report you should describe how you approached the task. You should describe:\n",
    "- Encountered difficulties (due to the method, e.g. \"not enough training samples to converge\", not technical like \"I could not install a package over pip\")\n",
    "- Steps taken to alleviate difficulties\n",
    "- General description of what you did, explain how you understood the task and what you did to solve it in general language, no code.\n",
    "- Potential limitations of your approach, what could be issues, how could this be hard on different data or with slightly different conditions\n",
    "- If you have an idea how this could be extended in an interesting way, describe it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fb915-f1a3-4044-a2f5-b63b9e15ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  # For tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33287f5-d864-4b09-b0a0-fe077f9545a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load and preprocess the IMDb dataset\n",
    "# IMDb dataset can be loaded from torchtext or manually via pandas\n",
    "from torchtext.datasets import IMDB\n",
    "\n",
    "# Load IMDb dataset\n",
    "train_data, test_data = IMDB(split=('train', 'test'))\n",
    "\n",
    "# Convert the data into lists\n",
    "train_data = [(label, text) for label, text in train_data]\n",
    "test_data = [(label, text) for label, text in test_data]\n",
    "\n",
    "# Combine the datasets for label propagation\n",
    "data = train_data + test_data\n",
    "\n",
    "# Convert to DataFrame for easier processing\n",
    "df = pd.DataFrame(data, columns=['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612cbfc-672d-4ff5-9c4e-9ebebcc5d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tip. You can get the dataset from torchtext but the package is old and needs pytorch version 2.2 to work\n",
    "## If you want to use it choose your versions like this: \n",
    "## !pip install -U torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu121 torchtext\n",
    "# from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84585960-7a22-434c-b1b5-89dcf3229af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Implement tokenization and label propagation\n",
    "# Implement a function to calculate sentiment scores for each word based on sentence-level labels.\n",
    "# The function should propagate labels to individual words and calculate a soft score for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca06a79-1b47-4fde-97a7-eeeec9304293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: You can use word_tokenize for tokenization\n",
    "# Hint: You can use a dictionary to store counts of positive and negative labels for each word.\n",
    "\n",
    "# Task 3: Prepare data for contextual learning\n",
    "# Implement a class to create a dataset with context windows. \n",
    "# Each data point should include the word embedding for the target word, \n",
    "# as well as an averaged embedding of the context words in a defined window size.\n",
    "\n",
    "# Use a pre-trained embedding model like GloVe. Download the embeddings and load them into a dictionary.\n",
    "# Example: {\"word\": embedding_vector}\n",
    "\n",
    "# Class signature example:\n",
    "# class WordContextDataset(Dataset):\n",
    "#     def __init__(self, df, word_scores, embedding_model, window_size=2):\n",
    "#         # Your code here\n",
    "#         pass\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         # Your code here\n",
    "#         pass\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         # Your code here\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf77713-74e7-40c7-b50d-5f42dd28466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Define and train the model\n",
    "# Define a neural network for sentiment classification using PyTorch.\n",
    "# The network should take an input vector of concatenated word and context embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d625da-c09a-443b-8c2c-795e01d750d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "# class SentimentClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SentimentClassifier, self).__init__()\n",
    "#         # Your code here\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Your code here\n",
    "#         pass\n",
    "\n",
    "# Implement a training loop to train the model on the dataset created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beed1f0-9b85-4121-801f-b8217996f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Evaluate the model\n",
    "# Evaluate the trained model on a validation set.\n",
    "# Use metrics such as precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df935c85-b28c-4b88-9d14-9104095272d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to evaluate the model:\n",
    "# with torch.no_grad():\n",
    "#     # Predict on validation data and calculate metrics\n",
    "#     pass\n",
    "\n",
    "# Optional: Experiment with hyperparameters or model architecture to improve performance.\n",
    "# Examples: Try different window sizes, embedding dimensions, or additional layers in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
