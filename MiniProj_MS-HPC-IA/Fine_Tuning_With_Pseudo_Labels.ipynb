{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9ff7e9",
   "metadata": {},
   "source": [
    "\n",
    "# Fine-tuning a Pre-trained Image Classification Model\n",
    "\n",
    "In this project, you will work with a pre-trained image classification model and datasets such as MS COCO and Tiny ImageNet. The steps will guide you through loading the model, evaluating it, generating pseudo-labels, fine-tuning the model, and comparing results.\n",
    "\n",
    "### Tasks\n",
    "1. Load a pre-trained image classification model.\n",
    "2. Evaluate its performance on MS COCO (You need to decide what will be the ground truth label!).\n",
    "3. Use the pre-trained model to generate pseudo-labels for Tiny ImageNet.\n",
    "4. Fine-tune the model using pseudo-labeled images.\n",
    "5. Compare the model's performance before and after fine-tuning.\n",
    "\n",
    "**Important**: At the end you should write a report of adequate size, which will probably mean at least half a page. In the report you should describe how you approached the task. You should describe:\n",
    "- Encountered difficulties (due to the method, e.g. \"not enough training samples to converge\", not technical like \"I could not install a package over pip\")\n",
    "- Steps taken to alleviate difficulties\n",
    "- General description of what you did, explain how you understood the task and what you did to solve it in general language, no code.\n",
    "- Potential limitations of your approach, what could be issues, how could this be hard on different data or with slightly different conditions\n",
    "- If you have an idea how this could be extended in an interesting way, describe it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7db69",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Setup and Load Required Libraries\n",
    "\n",
    "We will begin by setting up the necessary environment and importing the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CocoDetection, ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18 # You can use mobilenet small as alternative depending on your hardware. See https://pytorch.org/vision/main/models/mobilenetv3.html\n",
    "import os\n",
    "\n",
    "# Verify GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1518d9f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Load a Pre-trained Model\n",
    "\n",
    "We will use ResNet-18, a lightweight pre-trained model, which is efficient and performs well for classification tasks. You can also use Mobilenet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df23cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet-18 model\n",
    "model = resnet18(pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336a52c",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Load and Evaluate the Model on MS COCO\n",
    "\n",
    "### Steps:\n",
    "1. Use torchvision's `CocoDetection` to load a small subset of MS COCO.\n",
    "2. Perform evaluation using a few images and calculate the accuracy. (You can also use pycocotools for everything.\n",
    "3. Write code to handle image loading and transformations.\n",
    "\n",
    "**Task:** Complete the data loader and evaluation function. Note. In MS COCO each image has potentially several labels. They will have different bounding box sizes. You need to decide how to handle the ground truth label. Either you accept any label as correct that belongs to an image or you count the amount of objects of a specific class or sizes of bounding boxes to determine the best ground truth label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data transformations\n",
    "coco_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), # Resize images for faster processing\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "coco_dataset = CocoDetection(\n",
    "    root='path/to/coco/train2017',\n",
    "    annFile='path/to/coco/annotations/instances_train2017.json',\n",
    "    transform=coco_transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader\n",
    "coco_loader = DataLoader(coco_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "# Define an evaluation function (to be implemented by students)\n",
    "def evaluate_model_on_coco(model, data_loader):\n",
    "    pass\n",
    "\n",
    "# accuracy = evaluate_model_on_coco(model, coco_loader)\n",
    "# print(f\"Model accuracy on MS COCO: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898b8fa",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Generate Pseudo Labels for Tiny ImageNet\n",
    "\n",
    "The goal here is to ignore the labels of tiny imagenet for now and instead create your own database using the model you loaded before. The labels of the images will be predicted by the model and you need to save the predictions in a way that you can access them later for training.\n",
    "\n",
    "### Steps:\n",
    "1. Load the Tiny ImageNet dataset using torchvision's `ImageFolder`.\n",
    "2. Use the pre-trained model to assign pseudo-labels to each image.\n",
    "3. Save the pseudo-labeled dataset.\n",
    "\n",
    "**Task:** Complete the loop to generate pseudo-labels.\n",
    "\n",
    "Note, for a good training you may want to add Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for Tiny ImageNet\n",
    "tiny_imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), # Resize images for faster processing\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "# Load Tiny ImageNet dataset (modify the path to point to your dataset location)\n",
    "tiny_imagenet_dataset = ImageFolder(root='path/to/tiny-imagenet', transform=tiny_imagenet_transform)\n",
    "\n",
    "# Create a DataLoader\n",
    "tiny_imagenet_loader = DataLoader(tiny_imagenet_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Generate pseudo-labels\n",
    "pseudo_labels = []\n",
    "for images, _ in tiny_imagenet_loader:\n",
    "    images = images.to(device)\n",
    "    # Use the model to generate pseudo-labels for images\n",
    "    pass\n",
    "\n",
    "# Save pseudo-labeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda0143",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Fine-tune the Model\n",
    "\n",
    "### Steps:\n",
    "1. Train the pre-trained model on the pseudo-labeled Tiny ImageNet dataset.\n",
    "2. Use a small number of epochs and reduced batch size for efficiency.\n",
    "\n",
    "**Task:** Complete the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training loop (students to complete)\n",
    "def fine_tune_model(model, data_loader, optimizer, criterion, epochs=5):\n",
    "    # Task for students: Implement the fine-tuning loop\n",
    "    pass\n",
    "\n",
    "# Example setup for optimizer and criterion\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tune the model \n",
    "# fine_tune_model(model, pseudo_labeled_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7c9c8",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6: Evaluate and Compare Performance\n",
    "\n",
    "### Steps:\n",
    "1. Evaluate the model's performance on the Tiny ImageNet test set before and after fine-tuning.\n",
    "2. Plot and compare the results.\n",
    "\n",
    "**Task:** Implement the evaluation and comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c70d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "# final_accuracy = evaluate_model_on_tiny_imagenet(model, test_loader)\n",
    "# print(f\"Model accuracy on Tiny ImageNet after fine-tuning: {final_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ac366-8aa5-4cd2-bbea-c8d316975a66",
   "metadata": {},
   "source": [
    "# Note \n",
    "At this point the performance of a pre-trained model may actually go down because it was trained for a long time on a large dataset like Imagenet. The solution here is to train the model on the large dataset AND the new pseudo-labeled dataset. However, that is not realistic given the time for this exercise. Therefore in order to see how and if the performance through pseudo-labeling improves here is one final exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cff2f9-1416-4882-80f8-d5d33b78d7d8",
   "metadata": {},
   "source": [
    "# Bonus Steps: \n",
    "1. Repeat the process but this time do not use a pre-trained model but train on a subset of MS COCO\n",
    "2. Finetune on the subset and the pseudo-labeled images\n",
    "\n",
    "Note: Because training on MS COCO would take too much time use a subset. In the following you find some code to help you but it is not in order. The point here is to do the pseudo-labeling of tiny imagenet images and then finetune on the subset of MS COCO and tiny imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115416a-c0c5-45e4-ace6-3f88fb761b29",
   "metadata": {},
   "source": [
    "### This code can be used to create a subset of MS COCO. It needs to be heavily adjusted to work with your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e37365-6212-4b7e-922f-d77c9b7965c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CocoDetection\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SubsetCocoDataset(Dataset):\n",
    "    def __init__(self, coco_root, coco_ann_file, transform=None, subset_size=100):\n",
    "        \"\"\"\n",
    "        Custom Dataset that loads a random subset of the MS COCO dataset.\n",
    "\n",
    "        Args:\n",
    "            coco_root (str): Path to the root directory of COCO images.\n",
    "            coco_ann_file (str): Path to the annotation file.\n",
    "            transform (callable, optional): A function/transform to apply to images.\n",
    "            subset_size (int): Number of random samples to include in the subset.\n",
    "        \"\"\"\n",
    "        self.coco = CocoDetection(root=coco_root, annFile=coco_ann_file, transform=transform)\n",
    "        self.transform = transform\n",
    "        self.subset_size = subset_size\n",
    "\n",
    "        # Select a random subset of indices\n",
    "        self.indices = random.sample(range(len(self.coco)), subset_size)\n",
    "        self.subset = [self.coco[i] for i in self.indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.subset[idx]\n",
    "\n",
    "# Example usage:\n",
    "# transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
    "# coco_subset = SubsetCocoDataset(\n",
    "#     coco_root='path/to/coco/images',\n",
    "#     coco_ann_file='path/to/coco/annotations',\n",
    "#     transform=transform,\n",
    "#     subset_size=500  # Select 500 samples randomly\n",
    "# )\n",
    "# coco_loader = DataLoader(coco_subset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f202f-4273-4c5c-8d62-32902a12608e",
   "metadata": {},
   "source": [
    "### The following code can be used to combine datasets but needs to be heavily adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467bfdc0-146d-43dd-a8d9-9ef16904ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, datasets, transform=None):\n",
    "        \"\"\"\n",
    "        Combines multiple datasets into one.\n",
    "\n",
    "        Args:\n",
    "            datasets (list): List of datasets to combine.\n",
    "            transform (callable, optional): Transformations to apply to images.\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.transform = transform\n",
    "\n",
    "        # Store cumulative lengths for indexing\n",
    "        self.cumulative_lengths = []\n",
    "        total = 0\n",
    "        for dataset in datasets:\n",
    "            total += len(dataset)\n",
    "            self.cumulative_lengths.append(total)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(dataset) for dataset in self.datasets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine which dataset the index falls into\n",
    "        for i, cumulative_length in enumerate(self.cumulative_lengths):\n",
    "            if idx < cumulative_length:\n",
    "                # Adjust index to be relative to the dataset\n",
    "                dataset_idx = idx if i == 0 else idx - self.cumulative_lengths[i - 1]\n",
    "                image, label = self.datasets[i][dataset_idx]\n",
    "                \n",
    "                # Apply transforms if provided\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                \n",
    "                return image, label\n",
    "\n",
    "        raise IndexError(\"Index out of bounds for CombinedDataset\")\n",
    "\n",
    "# Example usage:\n",
    "# coco_dataset = SubsetCocoDataset(coco_root='path/to/coco/images', coco_ann_file='path/to/coco/annotations', subset_size=500)\n",
    "# tiny_imagenet_dataset = ImageFolder(root='path/to/tiny-imagenet', transform=tiny_imagenet_transform)\n",
    "# combined_dataset = CombinedDataset([coco_dataset, tiny_imagenet_dataset])\n",
    "\n",
    "# combined_loader = DataLoader(combined_dataset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad24dc-e946-4d93-828f-39d2309076e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c00471-4f92-4166-96b8-aab23055075a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0d42f-50af-4628-b3a9-55943c801557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_course_env",
   "language": "python",
   "name": "dl_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
