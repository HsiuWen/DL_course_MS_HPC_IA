{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expanded-defensive",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Encoder is the process that produce `new features` representation from the `old features`, either by selection or extraction, and decoder the reverse process. When the dimension of the new features (n_d) is relative low compare to the dimension of the old feature (n_e), we call this Dimensionality reduction. This is a popular processfor for data compression such as video, audio, etc. The main purpose of dimensionality reduction method is to find the best encoder/decoder pair among a give family. \n",
    "\n",
    "Hereafter, we denote E and D as the families of encoders and decoder, respectively. We define the reconstruction error measure between the input data x and the encoder data d(e(x)) as $\\epsilon(x,d(e(x))$. Then we can formulate this problem as:\n",
    "\n",
    "$$(e^*,d^*) = \\underset{(e,d)\\in ExD}{\\operatorname{argmax}}{\\epsilon(x, d(e(x)))}$$\n",
    "\n",
    "The general idea of autoencoders is simple that we try to learn the best encorder and decoder as neural networks using an iterative optimisation processs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "global-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-assault",
   "metadata": {},
   "source": [
    "Now let's try to do this on MINST images of digits. Note that the size of the image is 28x28 pixels. To accelerate the training process, we can use transformation functions in torchvision. Here we will apply normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "auburn-drinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'files', 'imagenet_classes.txt', 'input.jpg', 'input2.jpg', 'input3.jpg', 'L1b_what_NN_see_input.ipynb', 'L1_Introduction_CNN_MNIST.ipynb', 'L2_Object_detection_and_tracking.ipynb', 'Lab5_generative_model.ipynb', 'Lb3_RNN_LSTM_language.ipynb', 'Lb4_reinforcement_learning_Q.ipynb', 'MiniProj_MS-HPC-IA', 'Mini_project_MS_HPC_IA.ipynb', 'README.md', 'Seq_to_Seq.png', 'session1_convnet.pdf', 'session2_detection.pdf', 'session3_RNN.pdf', 'session4_RL.pdf', 'session5_deep_generative_model.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "infectious-indianapolis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size_train = 10\n",
    "batch_size_test = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('~/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('~/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-invalid",
   "metadata": {},
   "source": [
    "Now we should check the data to before we define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "quiet-falls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image shape in tensor: torch.Size([10, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get minibatch\n",
    "x,target = next(iter(train_loader)); x_test,_ = next(iter(test_loader))\n",
    "print('Loaded image shape in tensor:', x.size())\n",
    "fig,axes = plt.subplots(1,2); plt.set_cmap(['gray','viridis'][1]);\n",
    "axes[0].imshow(x[0][0].numpy()); axes[1].imshow(x_test[0][0].detach().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "committed-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "encoding_dim = 32\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ordinary-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size, encoding_dim), \n",
    "             nn.ReLU()])\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoding_dim, input_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(encoding_dim, input_size)])\n",
    "    \n",
    "    def forward(self,z):\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "        return z\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size = 784, encoding_dim = 32):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size, encoding_dim)\n",
    "        self.decoder = Decoder(encoding_dim, input_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten to (nm, 1) vector\n",
    "        x = self.encoder(x) # here we get the latent z\n",
    "        x = self.decoder(x) # here we get the reconsturcted input\n",
    "        x = torch.sigmoid(x)\n",
    "        x = x.reshape(x.size(0), 1,28,28) # reshape this flatten vector to the original image size    \n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tired-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(784,32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-thong",
   "metadata": {},
   "source": [
    "Here is what the initial autoencoder generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "perceived-textbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axes = plt.subplots(1,2); plt.set_cmap(['gray','viridis'][1]);\n",
    "axes[0].imshow(x[0][0].numpy()); axes[1].imshow(autoencoder(x)[0][0].detach().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-speed",
   "metadata": {},
   "source": [
    "Now we move to define how our autoencoder should be trainned. In this function of `train` we directly include the test data process at the end of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "handed-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader = None, valloader = None, num_epochs = 1):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # name dataloaders for phrase\n",
    "    phases = ['train']\n",
    "    dataloaders = {'train':trainloader}\n",
    "    if valloader:\n",
    "        phases.append('valid')\n",
    "        dataloaders['valid'] = valloader\n",
    "        \n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adadelta(autoencoder.parameters())\n",
    "    #criterion = F.binary_cross_entropy(autoencoder(x), target)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}\\n{\"-\"*10}')\n",
    "        \n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss, running_correct, count = 0.0, 0, 0\n",
    "            for batch_idx, (x, y) in enumerate(dataloaders[phase]):\n",
    "                x,y = x.to(device), y.to(device)\n",
    "\n",
    "                # zero param gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward: track history if training phase\n",
    "                with torch.set_grad_enabled(phase=='train'): # pytorch >= 0.4\n",
    "                    outputs = model(x)\n",
    "                    loss    = criterion(outputs, x)\n",
    "                    preds,_ = torch.max(outputs,1) # for accuracy metric\n",
    "                    # backward & optimize if training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # stats\n",
    "                running_loss += loss.item() * x.size(0)\n",
    "                count += len(x)\n",
    "            \n",
    "            epoch_loss = running_loss / count\n",
    "            print(f'{phase} loss {epoch_loss:.6f}')\n",
    "        print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "peripheral-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "train loss -39.771799\n",
      "valid loss -45.516923\n",
      "\n",
      "CPU times: user 42.6 s, sys: 9.06 s, total: 51.6 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%time train(autoencoder, trainloader=train_loader, valloader=test_loader, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-damages",
   "metadata": {},
   "source": [
    "Now we can plot the result of autoencoder to see how closs these two images are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "spread-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = next(iter(train_loader))\n",
    "#z = autoencoder(x)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "x = x.to(device)\n",
    "fig,axes = plt.subplots(1,2); plt.set_cmap(['gray','viridis'][1]);\n",
    "axes[0].imshow(x[0][0].cpu()); axes[1].imshow(autoencoder(x)[0][0].detach().cpu());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-remainder",
   "metadata": {},
   "source": [
    "## Limitation of autoencoder\n",
    "In the above example, our encoder and decoder architectures have only one layer without non-linearity. Such encoder-deocoder represent linear transformations (the sigmoid function can be removed since it is simply the function to accelerate the training). Our previous example has the same pricinple of principle componet anaysis (PCA). However, PCA define one of the soltuions (basis) that satisfied the minimum of reconstruction error while our autoencoder, indeed, can have several basis that describe the same optimal subspace. It ends up that the new features we have do not have to be independent.\n",
    "\n",
    "With deeper and more complex architectures, teh more the autoencoder can processed to high dimensionality reduction while keeping reconstruction loss low. It invokes an impoartant issue in traditional autoencoder: the lack of interpretable and exploitable structures in the latent space. Beside, once the autoencoder has been trained, we still have no way to produce any new content based on the trained latent space. Key to solve this issue: get the distribution of latent space so we can generate samples from this space ==> Variational Autoencoders (VAE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-olympus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test3",
   "language": "python",
   "name": "test3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
