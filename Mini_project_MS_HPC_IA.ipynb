{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HsiuWen/DL_course_MS_HPC_IA/blob/main/Mini_project_MS_HPC_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y6ehIVfhZ7b"
   },
   "source": [
    "# Deep-Learning mini-projects for the MS HPC-IA \n",
    "\n",
    "Pr. HsiuWen(Kelly) Chang Joly (Associate professor at the [center for Robotics](http://caor.mines-paristech.fr/), [MINES ParisTech](http://www.mines-paristech.fr/), [PSL Universit√© Paris](https://www.univ-psl.fr/)\n",
    "\n",
    "Some of the topics have the description in jupter notebook and some of them in HTML. Please run this notebook not in Colab since it will not find the file in the folder. Run this description locally.\n",
    "\n",
    "You have to choose 1 of the 7 mini-projects topics below :\n",
    "\n",
    "## 1. Transfer-learning \n",
    "[Notebook](MiniProj_MS-HPC-IA/flowers_notebook.html)\n",
    "Dataset: [102-flowers](https://cloud.mines-paristech.fr/index.php/s/ekN3uXoJSrbbSD8)\n",
    "\n",
    "In order to obtain a convNet that is able to recognize types of flowers\n",
    "[NB: example code illustrating how to load pre-trained convNets, and\n",
    "then modify it; freeze some layers for transfer Learning are\n",
    "avilable on web [page](https://keras.io/applications/) \n",
    "Applications - Keras\n",
    "Documentation\n",
    "\n",
    "## 2. Recognition of hand gestures using LSTM \n",
    "\n",
    "[Notebook of intro]\n",
    "\n",
    "Dataset: [DHG/SHREC2017](https://cloud.mines-paristech.fr/index.php/s/OzF1Hu9ZyXSsfqN)\n",
    "\n",
    "Use this dataset for [recognition of hand gestures](MiniProj_MS-HPC-IA/handGesturesDHG_notebook.html) (represented by joints trajectories):compare [multiples 1D temporal convolutions temporelles 1D](MiniProj_MS-HPC-IA/devineau_2018_deep_learning_hand_gesture_pytorch_model_quickstart.html) and Recurrent LSTM Neural Network\n",
    "\n",
    "## 3. Training a semantic segmentation covnet\n",
    "\n",
    "[Notebook of intro](https://github.com/HsiuWen/DL_course_MS_HPC_IA/blob/main/MiniProj_MS-HPC-IA/semantic_segmentation_FCN_DeepLab_pyTorch.ipynb)\n",
    "\n",
    "Dataset: [simulator](https://cloud.mines-paristech.fr/index.php/s/Z7M1FuTOe4uf7pl) (produced by a simulator) containing images and\n",
    "associated semantic segmentation ground truth (=class target values for\n",
    "each pixel)\n",
    "\n",
    "## 4. Tracking objects in video\n",
    "As described in Lab3_masrk_r_cnn_yolo.ipynb\n",
    "\n",
    "## 5. Reinforement learning project\n",
    "\n",
    "As described in Lab5_reinforcement_learning_Q.ipynb\n",
    "\n",
    "Implement [DQN](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) on one of the Atari game (find the one that is challenging!)\n",
    "\n",
    "## 6. GAN project ()\n",
    "You can choose any open source dataset but you have to run at least two different version of GAN. You have to explain the performance and explain the experience you gain during the training. Summaries the challenging. \n",
    "\n",
    "## 7. Predict the location of the user in indoor area with only inertial measurement unit\n",
    "\n",
    "[Notebook](MiniProj_MS-HPC-IA/ML_smartphone_pdr.ipynb)\n",
    "Input data is one seconds of acceleration and angular rate data. Output data is the speed and the heading of the user. Your goal is to revise the output layer and compare the result between CNN and LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a2pq75LMhzJ"
   },
   "source": [
    "## What to submit?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysRG_Z2-kxhJ"
   },
   "source": [
    "In all cases, the result of your mini-project work should be\n",
    "provided as a NOTEBOOK containing \n",
    "1. runnable *code with execution results*\n",
    "2. text cells constains (a) explanation of DL training (b) analysis. (c) Summary of obtained results\n",
    "\n",
    "This notebook should be sent by e-mail at hsiu-wen.chang_joly@mines-paristech.fr\n",
    "\n",
    "Deadline: 03, Mar., 2024 (Midnight!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXXaZhA0hUTM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPBvZvYt2LVjTHmlt2leViL",
   "include_colab_link": true,
   "name": "Mini project MS HPC-IA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
